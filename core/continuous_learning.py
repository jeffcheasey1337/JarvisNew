"""
–ù–ï–ü–†–ï–†–´–í–ù–ê–Ø —Å–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è JARVIS 24/7
–ü–æ—Å—Ç–æ—è–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏–∑ –í–°–ï–• –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ –±–µ–∑ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
"""

import asyncio
import logging
from datetime import datetime, timedelta
from pathlib import Path
import json
import random
from typing import List, Dict, Set
import feedparser
import requests
from bs4 import BeautifulSoup
from duckduckgo_search import DDGS
import hashlib
import re
import time

logger = logging.getLogger(__name__)


class ContinuousLearning:
    """–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ 24/7"""
    
    def __init__(self, config, memory_system, nlp_processor):
        self.config = config
        self.memory = memory_system
        self.nlp = nlp_processor
        
        # –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è
        self.continuous_mode = config.get('autonomous_learning', {}).get('continuous', True)
        self.learning_speed = config.get('autonomous_learning', {}).get('speed', 'normal')  # slow, normal, fast, turbo
        
        # –¢–µ–º—ã –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è
        self.topics_of_interest = self._load_topics()
        
        # –£–∂–µ –∏–∑—É—á–µ–Ω–Ω—ã–µ URL
        self.learned_urls = set()
        
        # –û—á–µ—Ä–µ–¥—å –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        self.learning_queue = asyncio.Queue()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
        self.stats = {
            'start_time': datetime.now(),
            'articles_processed': 0,
            'knowledge_items': 0,
            'sources_processed': 0,
            'current_topic': None,
            'learning_speed_items_per_hour': 0,
            'uptime_hours': 0
        }
        
        # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
        self.all_sources = self._initialize_all_sources()
        
        logger.info(" –ù–ï–ü–†–ï–†–´–í–ù–ê–Ø —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è 24/7 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        logger.info(f" –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è: {self.learning_speed.upper()}")
            
        # –°—Å—ã–ª–∫–∞ –Ω–∞ GUI (–±—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ–∑–∂–µ)
        self.gui = None

    def _load_topics(self) -> List[str]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ —Ç–µ–º"""
        topics_file = Path("data/learning_topics.json")
        
        if topics_file.exists():
            with open(topics_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('topics', [])
        
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç–µ–º
        mega_topics = [
            # AI –∏ ML
            "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "–Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏", "deep learning",
            "computer vision", "NLP", "—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã", "GPT", "LLM", "AGI", "reinforcement learning",
            
            # –ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ (–≤—Å–µ —è–∑—ã–∫–∏)
            "Python", "JavaScript", "TypeScript", "Rust", "Go", "C++", "Java", "Kotlin",
            "Swift", "Ruby", "PHP", "Scala", "Haskell", "Elixir", "Clojure",
            
            # –§—Ä–µ–π–º–≤–æ—Ä–∫–∏
            "React", "Vue", "Angular", "Django", "FastAPI", "Flask", "Express",
            "Next.js", "PyTorch", "TensorFlow", "Keras", "scikit-learn",
            
            # DevOps –∏ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞
            "Docker", "Kubernetes", "AWS", "Azure", "GCP", "CI/CD", "GitHub Actions",
            "Terraform", "Ansible", "–º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å—ã", "serverless",
            
            # –ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            "PostgreSQL", "MongoDB", "Redis", "Elasticsearch", "–≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö",
            "ChromaDB", "Pinecone", "Qdrant",
            
            # –ù–∞—É–∫–∞
            "–∫–≤–∞–Ω—Ç–æ–≤–∞—è —Ñ–∏–∑–∏–∫–∞", "–∞—Å—Ç—Ä–æ—Ñ–∏–∑–∏–∫–∞", "–±–∏–æ–ª–æ–≥–∏—è", "—Ö–∏–º–∏—è", "–º–∞—Ç–µ–º–∞—Ç–∏–∫–∞",
            "–∫–≤–∞–Ω—Ç–æ–≤—ã–µ –∫–æ–º–ø—å—é—Ç–µ—Ä—ã", "—Ç–µ—Ä–º–æ—è–¥–µ—Ä–Ω—ã–π —Å–∏–Ω—Ç–µ–∑", "CRISPR", "–≥–µ–Ω–Ω–∞—è –∏–Ω–∂–µ–Ω–µ—Ä–∏—è",
            
            # –ö–æ—Å–º–æ—Å
            "SpaceX", "NASA", "Mars", "–∫–æ—Å–º–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "—Ä–∞–∫–µ—Ç—ã", "—Å–ø—É—Ç–Ω–∏–∫–∏",
            "–∞—Å—Ç—Ä–æ–Ω–æ–º–∏—è", "—ç–∫–∑–æ–ø–ª–∞–Ω–µ—Ç—ã",
            
            # –†–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞
            "—Ä–æ–±–æ—Ç—ã", "Boston Dynamics", "–∞–≤—Ç–æ–Ω–æ–º–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã", "–¥—Ä–æ–Ω—ã", "–±–µ—Å–ø–∏–ª–æ—Ç–Ω–∏–∫–∏",
            "–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–∞—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è",
            
            # –ë–ª–æ–∫—á–µ–π–Ω –∏ Web3
            "blockchain", "Ethereum", "Bitcoin", "–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã", "DeFi", "NFT",
            "Web3", "—Å–º–∞—Ä—Ç-–∫–æ–Ω—Ç—Ä–∞–∫—Ç—ã", "–¥–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–∞—Ü–∏—è",
            
            # –ú–µ–¥–∏—Ü–∏–Ω–∞ –∏ –±–∏–æ—Ç–µ—Ö
            "–±–∏–æ—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "–Ω–µ–π—Ä–æ—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
            "brain-computer interface", "–ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–µ–¥–∏—Ü–∏–Ω–∞", "–ò–ò –≤ –º–µ–¥–∏—Ü–∏–Ω–µ",
            
            # –≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞
            "—Å–æ–ª–Ω–µ—á–Ω–∞—è —ç–Ω–µ—Ä–≥–∏—è", "–≤–µ—Ç—Ä—è–Ω–∞—è —ç–Ω–µ—Ä–≥–∏—è", "—è–¥–µ—Ä–Ω–∞—è —ç–Ω–µ—Ä–≥–∏—è",
            "–±–∞—Ç–∞—Ä–µ–∏", "–Ω–∞–∫–æ–ø–∏—Ç–µ–ª–∏ —ç–Ω–µ—Ä–≥–∏–∏", "–≤–æ–¥–æ—Ä–æ–¥",
            
            # –ë–∏–∑–Ω–µ—Å –∏ —Å—Ç–∞—Ä—Ç–∞–ø—ã
            "—Å—Ç–∞—Ä—Ç–∞–ø—ã", "–≤–µ–Ω—á—É—Ä–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª", "Y Combinator", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –±–∏–∑–Ω–µ—Å",
            "SaaS", "–º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏—è", "—Ä–æ—Å—Ç –ø—Ä–æ–¥—É–∫—Ç–∞",
            
            # –î–∏–∑–∞–π–Ω –∏ UX
            "UI/UX", "–¥–∏–∑–∞–π–Ω –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤", "Figma", "–ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–µ",
            
            # –ö–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
            "–∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", "—ç—Ç–∏—á–Ω—ã–π —Ö–∞–∫–∏–Ω–≥", "–ø–µ–Ω—Ç–µ—Å—Ç–∏–Ω–≥", "encryption",
            
            # AR/VR
            "–≤–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å", "–¥–æ–ø–æ–ª–Ω–µ–Ω–Ω–∞—è —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å", "–º–µ—Ç–∞–≤—Å–µ–ª–µ–Ω–Ω–∞—è",
            
            # –ò–≥—Ä—ã
            "gamedev", "Unity", "Unreal Engine", "–∏–Ω–¥–∏-–∏–≥—Ä—ã",
            
            # –û–±—â–µ–µ
            "–∏–Ω–Ω–æ–≤–∞—Ü–∏–∏", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–Ω–¥—ã", "–±—É–¥—É—â–µ–µ", "–ø—Ä–æ—Ä—ã–≤—ã",
            "–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è", "–æ—Ç–∫—Ä—ã—Ç–∏—è", "–ø–∞—Ç–µ–Ω—Ç—ã"
        ]
        
        self._save_topics(mega_topics)
        return mega_topics
    
    def _save_topics(self, topics: List[str]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–º"""
        Path("data").mkdir(exist_ok=True)
        with open("data/learning_topics.json", 'w', encoding='utf-8') as f:
            json.dump({'topics': topics}, f, ensure_ascii=False, indent=2)
    
    def _initialize_all_sources(self) -> Dict:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –í–°–ï–• –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        return {
            # RSS-–ª–µ–Ω—Ç—ã (–Ω–æ–≤–æ—Å—Ç–∏ –∏ –±–ª–æ–≥–∏)
            'rss': [
                {'name': 'Habr AI', 'url': 'https://habr.com/ru/rss/hub/artificial_intelligence/all/'},
                {'name': 'Habr ML', 'url': 'https://habr.com/ru/rss/hub/machine_learning/all/'},
                {'name': 'Habr Python', 'url': 'https://habr.com/ru/rss/hub/python/all/'},
                {'name': 'ArXiv AI', 'url': 'http://export.arxiv.org/rss/cs.AI'},
                {'name': 'ArXiv ML', 'url': 'http://export.arxiv.org/rss/cs.LG'},
                {'name': 'MIT News AI', 'url': 'https://news.mit.edu/topic/mitartificial-intelligence2-rss.xml'},
                {'name': 'TechCrunch', 'url': 'https://techcrunch.com/feed/'},
                {'name': 'Hacker News', 'url': 'https://news.ycombinator.com/rss'},
                {'name': 'Medium AI', 'url': 'https://medium.com/feed/tag/artificial-intelligence'},
                {'name': 'OpenAI Blog', 'url': 'https://openai.com/blog/rss.xml'},
            ],
            
            # –ü–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã (–ø–æ—Å—Ç–æ—è–Ω–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º—ã–µ)
            'search_patterns': [
                "{topic} latest news",
                "{topic} breakthrough 2025",
                "{topic} tutorial",
                "{topic} best practices",
                "{topic} research papers",
                "new {topic} technology",
                "{topic} innovations",
                "{topic} trends 2025"
            ],
            
            # Reddit (—Å–æ–æ–±—â–µ—Å—Ç–≤–∞)
            'reddit': [
                'MachineLearning', 'artificial', 'deeplearning', 'learnmachinelearning',
                'programming', 'Python', 'javascript', 'webdev', 'datascience',
                'science', 'Futurology', 'technology', 'coding', 'compsci'
            ],
            
            # GitHub (—Ç—Ä–µ–Ω–¥–æ–≤—ã–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏)
            'github_trending': ['python', 'javascript', 'typescript', 'rust', 'go'],
            
            # Stack Overflow (–Ω–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã/–æ—Ç–≤–µ—Ç—ã)
            'stackoverflow_tags': ['python', 'javascript', 'machine-learning', 'deep-learning', 'ai'],
            
            # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤
            'documentation': [
                'https://pytorch.org/docs/',
                'https://www.tensorflow.org/api_docs',
                'https://fastapi.tiangolo.com/',
                'https://react.dev/learn'
            ],
            
            # –ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            'academic': [
                'https://arxiv.org/',
                'https://scholar.google.com/',
                'https://www.semanticscholar.org/'
            ]
        }
    
    def _get_learning_delay(self) -> float:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–¥–µ—Ä–∂–∫–∏ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏"""
        delays = {
            'slow': 300,      # 5 –º–∏–Ω—É—Ç –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            'normal': 60,     # 1 –º–∏–Ω—É—Ç–∞
            'fast': 10,       # 10 —Å–µ–∫—É–Ω–¥
            'turbo': 1        # 1 —Å–µ–∫—É–Ω–¥–∞ (–ê–ì–†–ï–°–°–ò–í–ù–û!)
        }
        return delays.get(self.learning_speed, 60)
    
    async def start_continuous_learning(self):
        """
        –ó–∞–ø—É—Å–∫ –ù–ï–ü–†–ï–†–´–í–ù–û–ì–û –æ–±—É—á–µ–Ω–∏—è 24/7
        –†–∞–±–æ—Ç–∞–µ—Ç –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –≤ —Ñ–æ–Ω–µ, –±–µ–∑ –æ—Å—Ç–∞–Ω–æ–≤–æ–∫
        """
        if not self.continuous_mode:
            logger.info("‚è∏  –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ")
            return
        
        logger.info("="*70)
        logger.info(" –ó–ê–ü–£–°–ö –ù–ï–ü–†–ï–†–´–í–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø 24/7")
        logger.info("="*70)
        logger.info(f" –†–µ–∂–∏–º: {self.learning_speed.upper()}")
        logger.info(f"‚è±  –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏: {self._get_learning_delay()}—Å–µ–∫")
        logger.info(f" –¢–µ–º –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è: {len(self.topics_of_interest)}")
        logger.info(" –ù–∞—á–∏–Ω–∞—é –≤–ø–∏—Ç—ã–≤–∞—Ç—å –∑–Ω–∞–Ω–∏—è –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞...")
        logger.info("="*70)
        
        # –ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –æ–±—É—á–µ–Ω–∏—è
        tasks = [
            asyncio.create_task(self._continuous_rss_learning()),
            asyncio.create_task(self._continuous_search_learning()),
            asyncio.create_task(self._continuous_trending_learning()),
            asyncio.create_task(self._stats_updater()),
            asyncio.create_task(self._knowledge_consolidator())
        ]
        
        await asyncio.gather(*tasks, return_exceptions=True)
    
    async def _continuous_rss_learning(self):
        """–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –∏–∑—É—á–µ–Ω–∏–µ RSS-–ª–µ–Ω—Ç"""
        logger.info(" –ü–æ—Ç–æ–∫ RSS-–ª–µ–Ω—Ç: –ó–ê–ü–£–©–ï–ù")
        
        while True:
            try:
                for source in self.all_sources['rss']:
                    try:
                        feed = feedparser.parse(source['url'])
                        
                        for entry in feed.entries[:3]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Å—Ç–∞—Ç—å–∏
                            await self._process_article(
                                title=entry.get('title', ''),
                                content=entry.get('summary', ''),
                                url=entry.get('link', ''),
                                source=source['name'],
                                category='RSS'
                            )
                        
                        await asyncio.sleep(2)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
                        
                    except Exception as e:
                        logger.debug(f"–û—à–∏–±–∫–∞ RSS {source['name']}: {e}")
                
                # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º —Ü–∏–∫–ª–æ–º
                await asyncio.sleep(self._get_learning_delay())
                
            except Exception as e:
                logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ RSS –ø–æ—Ç–æ–∫–∞: {e}")
                await asyncio.sleep(60)
    
    async def _continuous_search_learning(self):
        """–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π –ø–æ–∏—Å–∫ –∏ –∏–∑—É—á–µ–Ω–∏–µ"""
        logger.info(" –ü–æ—Ç–æ–∫ WEB-–ü–û–ò–°–ö–ê: –ó–ê–ü–£–©–ï–ù")
        
        while True:
            try:
                # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—É—é —Ç–µ–º—É
                topic = random.choice(self.topics_of_interest)
                self.stats['current_topic'] = topic
                
                # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –ø–æ–∏—Å–∫–∞
                pattern = random.choice(self.all_sources['search_patterns'])
                query = pattern.format(topic=topic)
                
                logger.info(f" –ò–∑—É—á–∞—é: {query}")
                
                # –ü–æ–∏—Å–∫
                with DDGS() as ddgs:
                    results = list(ddgs.text(query, max_results=5))
                
                for result in results:
                    await self._process_article(
                        title=result.get('title', ''),
                        content=result.get('body', ''),
                        url=result.get('href', ''),
                        source='Web Search',
                        category=topic
                    )
                
                await asyncio.sleep(self._get_learning_delay())
                
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
                await asyncio.sleep(30)
    
    async def _continuous_trending_learning(self):
        """–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –∏–∑—É—á–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤"""
        logger.info(" –ü–æ—Ç–æ–∫ –¢–†–ï–ù–î–û–í: –ó–ê–ü–£–©–ï–ù")
        
        trending_queries = [
            "AI breakthroughs today",
            "latest technology news",
            "programming trends 2025",
            "–Ω–∞—É—á–Ω—ã–µ –æ—Ç–∫—Ä—ã—Ç–∏—è",
            "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏",
            "AI research papers",
            "github trending",
            "hacker news top"
        ]
        
        while True:
            try:
                query = random.choice(trending_queries)
                
                with DDGS() as ddgs:
                    results = list(ddgs.text(query, max_results=3))
                
                for result in results:
                    await self._process_article(
                        title=result.get('title', ''),
                        content=result.get('body', ''),
                        url=result.get('href', ''),
                        source='Trending',
                        category='Trend'
                    )
                
                await asyncio.sleep(self._get_learning_delay() * 2)
                
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ —Ç—Ä–µ–Ω–¥–æ–≤: {e}")
                await asyncio.sleep(60)

    async def _process_article(self, title: str, content: str, url: str, source: str, category: str):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏"""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞, –Ω–µ –∏–∑—É—á–∞–ª–∏ –ª–∏ —É–∂–µ
            url_hash = hashlib.md5(url.encode()).hexdigest()
            if url_hash in self.learned_urls:
                return

            if not title or not content:
                return

            # –°–æ–∑–¥–∞–Ω–∏–µ –∑–Ω–∞–Ω–∏—è
            knowledge = f"[{category}] {title}. {content[:500]}"

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ø–∞–º—è—Ç—å
            metadata = {
                'source': source,
                'category': category,
                'url': url,
                'learned_at': datetime.now().isoformat(),
                'importance': 0.7
            }

            await self.memory.store_memory(
                knowledge,
                memory_type="continuous_learning",
                metadata=metadata
            )

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ GUI –ø–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            self.stats['knowledge_items'] += 1
            if hasattr(self, 'gui') and self.gui:
                self.gui.add_log(f"[–û–ë–£–ß–ï–ù–ò–ï] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —Å—Ç–∞—Ç—å—è: {title[:50]}...")
                self.gui.update_stat('memory_items', self.stats['knowledge_items'])

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self.learned_urls.add(url_hash)
            self.stats['articles_processed'] += 1
            self.stats['sources_processed'] += 1

            logger.info(f" [{self.stats['articles_processed']}] {title[:60]}...")

        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç–∞—Ç—å–∏: {e}")
    
    async def _stats_updater(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
        logger.info(" –ü–æ—Ç–æ–∫ –°–¢–ê–¢–ò–°–¢–ò–ö–ò: –ó–ê–ü–£–©–ï–ù")
        
        while True:
            try:
                # –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–±–æ—Ç—ã
                uptime = datetime.now() - self.stats['start_time']
                self.stats['uptime_hours'] = uptime.total_seconds() / 3600
                
                # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (—ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ —á–∞—Å)
                if self.stats['uptime_hours'] > 0:
                    self.stats['learning_speed_items_per_hour'] = int(
                        self.stats['knowledge_items'] / self.stats['uptime_hours']
                    )
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
                await asyncio.sleep(300)
                
                logger.info("="*70)
                logger.info(" –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ù–ï–ü–†–ï–†–´–í–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
                logger.info(f"‚è∞ –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {self.stats['uptime_hours']:.2f} —á–∞—Å–æ–≤")
                logger.info(f" –ò–∑—É—á–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {self.stats['articles_processed']}")
                logger.info(f"üß† –ó–Ω–∞–Ω–∏–π –ø–æ–ª—É—á–µ–Ω–æ: {self.stats['knowledge_items']}")
                logger.info(f" –°–∫–æ—Ä–æ—Å—Ç—å: {self.stats['learning_speed_items_per_hour']} —ç–ª–µ–º–µ–Ω—Ç–æ–≤/—á–∞—Å")
                logger.info(f" –¢–µ–∫—É—â–∞—è —Ç–µ–º–∞: {self.stats['current_topic']}")
                logger.info("="*70)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                self._save_stats()
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
                await asyncio.sleep(60)
    
    async def _knowledge_consolidator(self):
        """–ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–Ω–∞–Ω–∏–π"""
        logger.info(" –ü–æ—Ç–æ–∫ –ö–û–ù–°–û–õ–ò–î–ê–¶–ò–ò: –ó–ê–ü–£–©–ï–ù")
        
        while True:
            try:
                # –ö–∞–∂–¥—ã–π —á–∞—Å –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
                await asyncio.sleep(3600)
                
                logger.info(" –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –∑–Ω–∞–Ω–∏–π...")
                
                # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É:
                # - –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
                # - –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ—Ö–æ–∂–∏—Ö –∑–Ω–∞–Ω–∏–π
                # - –ü–æ–≤—ã—à–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏—Ö—Å—è —Ç–µ–º
                
                logger.info(" –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏: {e}")
                await asyncio.sleep(3600)
    
    def _save_stats(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        try:
            stats_file = Path("data/continuous_learning_stats.json")
            stats_file.parent.mkdir(exist_ok=True)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–ª—è JSON
            stats_to_save = self.stats.copy()
            stats_to_save['start_time'] = stats_to_save['start_time'].isoformat()
            
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(stats_to_save, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
    
    async def get_realtime_stats(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
        return {
            'uptime_hours': self.stats['uptime_hours'],
            'articles_total': self.stats['articles_processed'],
            'knowledge_items': self.stats['knowledge_items'],
            'speed_per_hour': self.stats['learning_speed_items_per_hour'],
            'current_topic': self.stats['current_topic'],
            'learning_mode': self.learning_speed,
            'sources_count': len(self.all_sources['rss'])
        }
    
    async def change_speed(self, new_speed: str):
        """–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –ª–µ—Ç—É"""
        if new_speed in ['slow', 'normal', 'fast', 'turbo']:
            self.learning_speed = new_speed
            logger.info(f" –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞: {new_speed.upper()}")
            return f"–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {new_speed}"
        return "–î–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∫–æ—Ä–æ—Å—Ç–∏: slow, normal, fast, turbo"
