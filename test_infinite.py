# -*- coding: utf-8 -*-
"""
üß™ –¢–ï–°–¢ INFINITE LEARNING SYSTEM
"""

import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s - %(message)s'
)

print("="*80)
print("üß™ –¢–ï–°–¢ –ë–ï–°–ö–û–ù–ï–ß–ù–û–ô –°–ò–°–¢–ï–ú–´ –û–ë–£–ß–ï–ù–ò–Ø")
print("="*80)
print()

print("–ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª—è...")
try:
    from infinite_learning_system import InfiniteLearningSystem
    print("‚úì –ú–æ–¥—É–ª—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
except Exception as e:
    print(f"‚úó –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    import traceback
    traceback.print_exc()
    input("\nEnter...")
    exit(1)

print()
print("="*80)
print("–¢–ï–°–¢–û–í–´–ô –ó–ê–ü–£–°–ö")
print("="*80)
print()

# –ù–∞—á–∞–ª—å–Ω—ã–µ —Ç–µ–º—ã
initial_topics = [
    "Python",
    "–ö–≤–µ–Ω—Ç–∏–Ω –¢–∞—Ä–∞–Ω—Ç–∏–Ω–æ",
]

print(f"–ù–∞—á–∞–ª—å–Ω—ã–µ —Ç–µ–º—ã: {initial_topics}")
print()

# –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É
system = InfiniteLearningSystem(initial_topics=initial_topics)

print("="*80)
print("–ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–æ 3 —Ç–µ–º–∞–º–∏ –¥–ª—è —Ç–µ—Å—Ç–∞)")
print("="*80)
print()

# –ó–∞–ø—É—Å–∫–∞–µ–º —Å –ª–∏–º–∏—Ç–æ–º 3 —Ç–µ–º—ã
try:
    system.start_infinite_learning(max_topics=3)
except KeyboardInterrupt:
    print("\n‚ö† –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
except Exception as e:
    print(f"\n‚úó –û—à–∏–±–∫–∞: {e}")
    import traceback
    traceback.print_exc()

print()
print("="*80)
print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ê")
print("="*80)
print()

# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Å–æ–±—Ä–∞–ª–∏
import json
from pathlib import Path

data_dir = Path('data/infinite_knowledge')

if data_dir.exists():
    files = list(data_dir.glob('*.json'))
    
    # –ò—Å–∫–ª—é—á–∞–µ–º –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π
    topic_files = [f for f in files if f.name != 'knowledge_graph.json']
    
    print(f"–ò–∑—É—á–µ–Ω–æ —Ç–µ–º: {len(topic_files)}")
    print()
    
    if topic_files:
        print("–ü—Ä–∏–º–µ—Ä—ã –∏–∑—É—á–µ–Ω–Ω—ã—Ö —Ç–µ–º:")
        for f in topic_files[:5]:
            with open(f, 'r', encoding='utf-8') as file:
                data = json.load(file)
                
                topic = data.get('content', '')[:50]
                sources = len(data.get('sources', []))
                entities = sum(len(v) for v in data.get('entities', {}).values())
                
                print(f"  ‚Ä¢ {f.stem}")
                print(f"    –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {sources}")
                print(f"    –ù–∞–π–¥–µ–Ω–æ —Å—É—â–Ω–æ—Å—Ç–µ–π: {entities}")
        
        print()
    
    # –ì—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π
    graph_file = data_dir / 'knowledge_graph.json'
    if graph_file.exists():
        with open(graph_file, 'r', encoding='utf-8') as f:
            graph_data = json.load(f)
            
            graph = graph_data.get('graph', {})
            
            print(f"–ì—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π:")
            print(f"  –¢–µ–º –≤ –≥—Ä–∞—Ñ–µ: {len(graph)}")
            print(f"  –°–≤—è–∑–µ–π: {sum(len(v) for v in graph.values())}")
            print()
            
            if graph:
                print("–ü—Ä–∏–º–µ—Ä—ã —Å–≤—è–∑–µ–π:")
                for topic, related in list(graph.items())[:3]:
                    print(f"  {topic} ‚Üí {list(related)[:3]}")
else:
    print("‚ö† –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

print()
print("="*80)
print()

if topic_files and len(topic_files) > 0:
    print("‚úÖ –¢–ï–°–¢ –£–°–ü–ï–®–ï–ù!")
    print()
    print("–°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç! –ú–æ–∂–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ JARVIS:")
    print("  python integrate_infinite.py")
else:
    print("‚ö† –ü–†–û–ë–õ–ï–ú–´")
    print()
    print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:")
    print("  1. –ò–Ω—Ç–µ—Ä–Ω–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω")
    print("  2. Wikipedia –¥–æ—Å—Ç—É–ø–Ω–∞")
    print("  3. –ù–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫")

print()
print("="*80)

input("\nEnter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")
