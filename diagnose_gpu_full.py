# -*- coding: utf-8 -*-
"""
üîç –ü–û–õ–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê GPU
–î–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ GPU
"""

import subprocess
import sys

print("="*80)
print("üîç –ü–û–õ–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê RTX 4070 Ti SUPER")
print("="*80)
print()

# ============================================================================
# 1. NVIDIA-SMI –î–ï–¢–ê–õ–ò
# ============================================================================
print("[1/7] –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è nvidia-smi...")
print()

try:
    result = subprocess.run(['nvidia-smi', '-q'], capture_output=True, text=True, timeout=5)
    
    if result.returncode == 0:
        lines = result.stdout.split('\n')
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        for line in lines:
            if any(keyword in line for keyword in [
                'Product Name',
                'Driver Version',
                'CUDA Version',
                'GPU Current Temp',
                'Performance State',
                'Power Draw',
                'Power Limit',
                'FB Memory Usage',
                'Compute Mode',
                'GPU Clocks',
            ]):
                print(f"  {line.strip()}")
        
        print()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Compute Mode
        compute_mode = None
        for line in lines:
            if 'Compute Mode' in line:
                compute_mode = line.split(':')[1].strip()
                break
        
        if compute_mode and compute_mode != 'Default':
            print(f"‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: Compute Mode = {compute_mode}")
            print("   –î–æ–ª–∂–Ω–æ –±—ã—Ç—å: Default")
            print()

except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    print()

# ============================================================================
# 2. PYTORCH CUDA –î–ï–¢–ê–õ–ò
# ============================================================================
print("[2/7] PyTorch –∏ CUDA...")
print()

try:
    import torch
    
    print(f"PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
    print(f"CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDA –≤–µ—Ä—Å–∏—è (PyTorch): {torch.version.cuda}")
        print(f"cuDNN –≤–µ—Ä—Å–∏—è: {torch.backends.cudnn.version()}")
        print(f"cuDNN enabled: {torch.backends.cudnn.enabled}")
        print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU: {torch.cuda.device_count()}")
        print()
        
        for i in range(torch.cuda.device_count()):
            print(f"GPU {i}:")
            print(f"  –ò–º—è: {torch.cuda.get_device_name(i)}")
            print(f"  Capability: {torch.cuda.get_device_capability(i)}")
            print(f"  Total memory: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB")
            print()
        
        # ============================================================
        # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê - –í–ï–†–°–ò–Ø CUDA
        # ============================================================
        cuda_version = torch.version.cuda
        
        if cuda_version:
            major = int(cuda_version.split('.')[0])
            
            print("‚îÄ"*80)
            if major < 12:
                print("‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–ë–õ–ï–ú–ê –ù–ê–ô–î–ï–ù–ê!")
                print()
                print(f"   CUDA –≤–µ—Ä—Å–∏—è: {cuda_version}")
                print("   RTX 4070 Ti SUPER —Ç—Ä–µ–±—É–µ—Ç: CUDA 12.x")
                print()
                print("   –≠—Ç–æ –æ–±—ä—è—Å–Ω—è–µ—Ç –Ω–∏–∑–∫—É—é –∑–∞–≥—Ä—É–∑–∫—É GPU!")
                print()
                print("–†–ï–®–ï–ù–ò–ï:")
                print()
                print("1. pip uninstall torch torchvision torchaudio -y")
                print("2. pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
                print()
                print("‚îÄ"*80)
            else:
                print("‚úÖ CUDA –≤–µ—Ä—Å–∏—è OK (12.x)")
                print("‚îÄ"*80)
        
        print()
    
    else:
        print("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –≤ PyTorch!")
        print()

except ImportError:
    print("‚ùå PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
    print()

# ============================================================================
# 3. –ë–´–°–¢–†–´–ô GPU –¢–ï–°–¢
# ============================================================================
print("[3/7] –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç GPU...")
print()

try:
    import torch
    import time
    
    if torch.cuda.is_available():
        device = torch.device('cuda:0')
        
        print("–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–Ω–∑–æ—Ä–æ–≤ –Ω–∞ GPU...")
        x = torch.randn(5000, 5000, device=device)
        y = torch.randn(5000, 5000, device=device)
        
        print(f"VRAM –¥–æ –æ–ø–µ—Ä–∞—Ü–∏–∏: {torch.cuda.memory_allocated(0) / 1024**2:.0f} MB")
        
        print("–£–º–Ω–æ–∂–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü...")
        start = time.time()
        
        for i in range(10):
            z = torch.matmul(x, y)
        
        elapsed = time.time() - start
        
        print(f"VRAM –ø–æ—Å–ª–µ –æ–ø–µ—Ä–∞—Ü–∏–∏: {torch.cuda.memory_allocated(0) / 1024**2:.0f} MB")
        print(f"–í—Ä–µ–º—è: {elapsed:.3f} —Å–µ–∫")
        print(f"–°–∫–æ—Ä–æ—Å—Ç—å: {10/elapsed:.1f} ops/sec")
        print()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ–ø–µ—Ä–∞—Ü–∏—è –±—ã–ª–∞ –Ω–∞ GPU
        print("‚úì –û–ø–µ—Ä–∞—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã –Ω–∞ GPU")
        print()

except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    print()

# ============================================================================
# 4. –ü–†–û–í–ï–†–ö–ê TCC/WDDM –†–ï–ñ–ò–ú–ê
# ============================================================================
print("[4/7] –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∂–∏–º–∞ GPU (TCC/WDDM)...")
print()

try:
    result = subprocess.run(
        ['nvidia-smi', '-q', '-d', 'COMPUTE'],
        capture_output=True,
        text=True,
        timeout=5
    )
    
    if result.returncode == 0:
        if 'WDDM' in result.stdout:
            print("‚úì –†–µ–∂–∏–º: WDDM (–ø—Ä–∞–≤–∏–ª—å–Ω–æ –¥–ª—è Windows)")
        elif 'TCC' in result.stdout:
            print("‚ö†Ô∏è  –†–µ–∂–∏–º: TCC (—Ä–µ–∂–∏–º Data Center)")
            print("   –î–ª—è –∏–≥—Ä–æ–≤—ã—Ö –∫–∞—Ä—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å WDDM")
            print()
            print("–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç–µ –≤ WDDM:")
            print("  nvidia-smi -dm 0")
            print()
        else:
            print("? –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–µ–∂–∏–º")
        
        print()

except Exception as e:
    print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å: {e}")
    print()

# ============================================================================
# 5. –ü–†–û–í–ï–†–ö–ê PCI-E
# ============================================================================
print("[5/7] –ü—Ä–æ–≤–µ—Ä–∫–∞ PCI-E –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è...")
print()

try:
    result = subprocess.run(
        ['nvidia-smi', '-q', '-d', 'PCIE'],
        capture_output=True,
        text=True,
        timeout=5
    )
    
    if result.returncode == 0:
        lines = result.stdout.split('\n')
        
        for line in lines:
            if any(keyword in line for keyword in [
                'Link Width',
                'Current Link Width',
                'Max Link Width',
                'Link Speed',
                'Current Link Speed',
            ]):
                print(f"  {line.strip()}")
        
        print()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ x16
        if 'x16' not in result.stdout:
            print("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: GPU –Ω–µ –≤ —Å–ª–æ—Ç–µ x16!")
            print("   –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–Ω–∏–∂–µ–Ω–∞")
            print()

except Exception as e:
    print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å: {e}")
    print()

# ============================================================================
# 6. –ü–†–û–í–ï–†–ö–ê –¢–ï–ú–ü–ï–†–ê–¢–£–†–ù–´–• –õ–ò–ú–ò–¢–û–í
# ============================================================================
print("[6/7] –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω—ã—Ö –ª–∏–º–∏—Ç–æ–≤...")
print()

try:
    result = subprocess.run(
        ['nvidia-smi', '--query-gpu=temperature.gpu,temperature.gpu.tlimit',
         '--format=csv,noheader'],
        capture_output=True,
        text=True,
        timeout=2
    )
    
    if result.returncode == 0:
        data = result.stdout.strip().split(',')
        current_temp = int(data[0])
        temp_limit = int(data[1]) if len(data) > 1 else 0
        
        print(f"–¢–µ–∫—É—â–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {current_temp}¬∞C")
        print(f"–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω—ã–π –ª–∏–º–∏—Ç: {temp_limit}¬∞C")
        
        if current_temp > temp_limit - 5:
            print()
            print("‚ö†Ô∏è  GPU –±–ª–∏–∑–∫–∞ –∫ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω–æ–º—É –ª–∏–º–∏—Ç—É!")
            print("   –ú–æ–∂–µ—Ç –≤–∫–ª—é—á–∞—Ç—å—Å—è —Ç—Ä–æ—Ç—Ç–ª–∏–Ω–≥")
            print()
        else:
            print("‚úì –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≤ –Ω–æ—Ä–º–µ")
        
        print()

except Exception as e:
    print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å: {e}")
    print()

# ============================================================================
# 7. –ü–†–û–í–ï–†–ö–ê POWER LIMIT
# ============================================================================
print("[7/7] –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ –º–æ—â–Ω–æ—Å—Ç–∏...")
print()

try:
    result = subprocess.run(
        ['nvidia-smi', '--query-gpu=power.draw,power.limit',
         '--format=csv,noheader,nounits'],
        capture_output=True,
        text=True,
        timeout=2
    )
    
    if result.returncode == 0:
        data = result.stdout.strip().split(',')
        power_draw = float(data[0])
        power_limit = float(data[1])
        
        print(f"–¢–µ–∫—É—â–∞—è –º–æ—â–Ω–æ—Å—Ç—å: {power_draw:.1f} W")
        print(f"–õ–∏–º–∏—Ç –º–æ—â–Ω–æ—Å—Ç–∏: {power_limit:.1f} W")
        print(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: {power_draw/power_limit*100:.1f}%")
        print()
        
        # RTX 4070 Ti SUPER –∏–º–µ–µ—Ç TDP 285W
        if power_limit < 250:
            print("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –õ–∏–º–∏—Ç –º–æ—â–Ω–æ—Å—Ç–∏ —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∏–π!")
            print(f"   –¢–µ–∫—É—â–∏–π: {power_limit:.0f}W")
            print("   –û–∂–∏–¥–∞–µ—Ç—Å—è: 285W –¥–ª—è RTX 4070 Ti SUPER")
            print()
            print("–≠—Ç–æ –º–æ–∂–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å!")
            print()
        else:
            print("‚úì –õ–∏–º–∏—Ç –º–æ—â–Ω–æ—Å—Ç–∏ OK")
            print()

except Exception as e:
    print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å: {e}")
    print()

# ============================================================================
# –ò–¢–û–ì–ò –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò
# ============================================================================
print("="*80)
print("üìã –ò–¢–û–ì–ò –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò")
print("="*80)
print()

print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–ª–µ–¥—É—é—â–µ–µ:")
print()

print("1. CUDA –≤–µ—Ä—Å–∏—è PyTorch:")
try:
    import torch
    cuda_ver = torch.version.cuda
    if cuda_ver:
        major = int(cuda_ver.split('.')[0])
        if major < 12:
            print(f"   ‚ùå CUDA {cuda_ver} - –°–õ–ò–®–ö–û–ú –°–¢–ê–†–ê–Ø!")
            print("   ‚úì –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyTorch —Å CUDA 12.1")
        else:
            print(f"   ‚úì CUDA {cuda_ver} - OK")
    else:
        print("   ‚ùå CUDA –≤–µ—Ä—Å–∏—è –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞")
except:
    print("   ‚ùå PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

print()
print("2. –î—Ä–∞–π–≤–µ—Ä NVIDIA:")
try:
    result = subprocess.run(
        ['nvidia-smi', '--query-gpu=driver_version', '--format=csv,noheader'],
        capture_output=True, text=True, timeout=2
    )
    if result.returncode == 0:
        driver = result.stdout.strip()
        major = int(driver.split('.')[0])
        if major < 525:
            print(f"   ‚ùå –î—Ä–∞–π–≤–µ—Ä {driver} - –£–°–¢–ê–†–ï–õ!")
            print("   ‚úì –û–±–Ω–æ–≤–∏—Ç–µ –¥–æ 525.60.11+")
        else:
            print(f"   ‚úì –î—Ä–∞–π–≤–µ—Ä {driver} - OK")
except:
    print("   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å")

print()
print("3. –†–µ–∂–∏–º GPU:")
print("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—ã—à–µ - –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å WDDM")

print()
print("4. PCI-E:")
print("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—ã—à–µ - –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å x16")

print()
print("5. –õ–∏–º–∏—Ç –º–æ—â–Ω–æ—Å—Ç–∏:")
print("   –î–æ–ª–∂–Ω–æ –±—ã—Ç—å ~285W –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")

print()
print("="*80)
print()

print("üî• –ì–õ–ê–í–ù–ê–Ø –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø:")
print()
print("–ï—Å–ª–∏ CUDA –≤–µ—Ä—Å–∏—è < 12.0:")
print()
print("  pip uninstall torch torchvision torchaudio -y")
print("  pip cache purge")
print("  pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
print()
print("–ó–∞—Ç–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç–µ:")
print("  python fix_rtx_4070_ti_super.py")
print()
print("="*80)

input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")
