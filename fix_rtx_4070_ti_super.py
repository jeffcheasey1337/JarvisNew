# -*- coding: utf-8 -*-
"""
üî• RTX 4070 Ti SUPER - CUDA 12.x FIX
–°–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –Ω–æ–≤—ã—Ö RTX 40-—Å–µ—Ä–∏–π

–ü—Ä–æ–±–ª–µ–º–∞: CUDA 11.7 –ù–ï –ü–û–î–î–ï–†–ñ–ò–í–ê–ï–¢ RTX 4070 Ti SUPER –ø–æ–ª–Ω–æ—Å—Ç—å—é!
–†–µ—à–µ–Ω–∏–µ: CUDA 12.1
"""

import sys
import subprocess
from pathlib import Path

print("="*80)
print("üî• RTX 4070 Ti SUPER - CUDA FIX")
print("="*80)
print()

# ============================================================================
# –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–ë–õ–ï–ú–ê
# ============================================================================
print("‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–ë–õ–ï–ú–ê –û–ë–ù–ê–†–£–ñ–ï–ù–ê!")
print()
print("–£ –≤–∞—Å: PyTorch 2.0.1+cu117 (CUDA 11.7)")
print("–ö–∞—Ä—Ç–∞: RTX 4070 Ti SUPER")
print()
print("‚ö†Ô∏è  RTX 4070 Ti SUPER (Ada Lovelace) —Ç—Ä–µ–±—É–µ—Ç CUDA 12.x!")
print("‚ö†Ô∏è  CUDA 11.7 –ù–ï –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —ç—Ç—É –∫–∞—Ä—Ç—É!")
print()
print("–≠—Ç–æ –æ–±—ä—è—Å–Ω—è–µ—Ç –ø–æ—á–µ–º—É GPU –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è!")
print()

# ============================================================================
# –ü–†–û–í–ï–†–ö–ê –î–†–ê–ô–í–ï–†–ê
# ============================================================================
print("–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä–∞–π–≤–µ—Ä–∞ NVIDIA...")
print()

try:
    result = subprocess.run(
        ['nvidia-smi', '--query-gpu=driver_version', '--format=csv,noheader'],
        capture_output=True,
        text=True,
        timeout=2
    )
    
    if result.returncode == 0:
        driver_version = result.stdout.strip()
        print(f"–í–µ—Ä—Å–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞: {driver_version}")
        
        # –î–ª—è RTX 4070 Ti SUPER –Ω—É–∂–µ–Ω –¥—Ä–∞–π–≤–µ—Ä 525.60.11+
        major_version = int(driver_version.split('.')[0])
        
        if major_version < 525:
            print()
            print("‚ùå –î–†–ê–ô–í–ï–† –£–°–¢–ê–†–ï–õ!")
            print(f"   –¢–µ–∫—É—â–∏–π: {driver_version}")
            print(f"   –¢—Ä–µ–±—É–µ—Ç—Å—è: 525.60.11+")
            print()
            print("–°–∫–∞—á–∞–π—Ç–µ –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥—Ä–∞–π–≤–µ—Ä:")
            print("https://www.nvidia.com/download/index.aspx")
            print()
        else:
            print(f"‚úì –î—Ä–∞–π–≤–µ—Ä OK ({driver_version} >= 525)")
            print()

except Exception as e:
    print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥—Ä–∞–π–≤–µ—Ä: {e}")
    print()

# ============================================================================
# –†–ï–®–ï–ù–ò–ï
# ============================================================================
print("="*80)
print("üîß –†–ï–®–ï–ù–ò–ï - 3 –®–ê–ì–ê")
print("="*80)
print()

print("–®–ê–ì 1: –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ PyTorch")
print("‚îÄ"*80)
print()
print("–í—ã–ø–æ–ª–Ω–∏—Ç–µ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ:")
print()
print("  pip uninstall torch torchvision torchaudio -y")
print()
input("–í—ã–ø–æ–ª–Ω–∏–ª–∏? –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
print()

print("–®–ê–ì 2: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch —Å CUDA 12.1")
print("‚îÄ"*80)
print()
print("–í—ã–ø–æ–ª–Ω–∏—Ç–µ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ:")
print()
print("  pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
print()
print("‚ö†Ô∏è  –í–ê–ñ–ù–û: cu121 - —ç—Ç–æ CUDA 12.1!")
print("‚ö†Ô∏è  –ù–ï cu117, –ù–ï cu118 - —Ç–æ–ª—å–∫–æ cu121!")
print()
input("–í—ã–ø–æ–ª–Ω–∏–ª–∏? –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
print()

print("–®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏")
print("‚îÄ"*80)
print()
print("–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ PyTorch —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ...")
print()

try:
    import torch
    
    print(f"PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
    print(f"CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Ä—Å–∏—é CUDA
        cuda_version = torch.version.cuda
        if cuda_version and cuda_version.startswith('12.'):
            print()
            print("‚úÖ –û–¢–õ–ò–ß–ù–û! PyTorch —Å CUDA 12.x —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
            print()
        else:
            print()
            print("‚ùå –û–®–ò–ë–ö–ê! PyTorch –≤—Å—ë –µ—â—ë —Å CUDA 11.x!")
            print()
            print("–í–æ–∑–º–æ–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏–ª–∞—Å—å –Ω–µ —Ç–∞ –≤–µ—Ä—Å–∏—è.")
            print("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —è–≤–Ω–æ:")
            print()
            print("  pip uninstall torch torchvision torchaudio -y")
            print("  pip cache purge")
            print("  pip install torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 --index-url https://download.pytorch.org/whl/cu121")
            print()
            input("–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")
            sys.exit(1)
    else:
        print()
        print("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞!")
        print()
        print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:")
        print("1. –î—Ä–∞–π–≤–µ—Ä—ã NVIDIA —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã?")
        print("2. nvidia-smi —Ä–∞–±–æ—Ç–∞–µ—Ç?")
        print()
        input("–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")
        sys.exit(1)

except ImportError:
    print("‚ùå PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
    print()
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ:")
    print("  pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
    print()
    input("–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")
    sys.exit(1)

# ============================================================================
# –ê–ì–†–ï–°–°–ò–í–ù–´–ô GPU –°–¢–†–ï–°–°-–¢–ï–°–¢
# ============================================================================
print()
print("="*80)
print("üî• –ê–ì–†–ï–°–°–ò–í–ù–´–ô GPU –°–¢–†–ï–°–°-–¢–ï–°–¢")
print("="*80)
print()

print("–°–µ–π—á–∞—Å –∑–∞–ø—É—Å—Ç–∏—Ç—Å—è —Ç–µ—Å—Ç –∫–æ—Ç–æ—Ä—ã–π –ì–ê–†–ê–ù–¢–ò–†–û–í–ê–ù–ù–û –∑–∞–≥—Ä—É–∑–∏—Ç GPU!")
print()
print("‚ö†Ô∏è  –û–¢–ö–†–û–ô–¢–ï –í–¢–û–†–û–ô –¢–ï–†–ú–ò–ù–ê–õ:")
print("    nvidia-smi -l 1")
print()
print("GPU –¥–æ–ª–∂–Ω–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å—Å—è –¥–æ 95-100%!")
print()
input("–ì–æ—Ç–æ–≤—ã? –ù–∞–∂–º–∏—Ç–µ Enter...")
print()

try:
    import torch
    
    device = torch.device('cuda:0')
    print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print()
    
    # –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞
    torch.cuda.empty_cache()
    
    # ========================================================================
    # –¢–ï–°–¢ 1: –û–ì–†–û–ú–ù–´–ï –ú–ê–¢–†–ò–¶–´
    # ========================================================================
    print("[–¢–ï–°–¢ 1/4] –£–º–Ω–æ–∂–µ–Ω–∏–µ –æ–≥—Ä–æ–º–Ω—ã—Ö –º–∞—Ç—Ä–∏—Ü...")
    print()
    
    import time
    
    # –°–æ–∑–¥–∞—ë–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±–æ–ª—å—à–∏–µ –º–∞—Ç—Ä–∏—Ü—ã
    print("–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü 15000x15000...")
    a = torch.randn(15000, 15000, device=device)
    b = torch.randn(15000, 15000, device=device)
    
    print(f"VRAM: {torch.cuda.memory_allocated(0) / 1024**2:.0f} MB")
    print()
    
    print("–£–º–Ω–æ–∂–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü (100 –∏—Ç–µ—Ä–∞—Ü–∏–π)...")
    start = time.time()
    
    for i in range(100):
        c = torch.matmul(a, b)
        
        if i % 10 == 0:
            print(f"  –ò—Ç–µ—Ä–∞—Ü–∏—è {i}/100 | "
                  f"VRAM: {torch.cuda.memory_allocated(0) / 1024**2:.0f} MB | "
                  f"GPU –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –Ω–∞ 100%!")
    
    elapsed = time.time() - start
    print(f"‚úì –ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {elapsed:.1f} —Å–µ–∫")
    print()
    
    # ========================================================================
    # –¢–ï–°–¢ 2: –ù–ï–ü–†–ï–†–´–í–ù–´–ï –û–ü–ï–†–ê–¶–ò–ò
    # ========================================================================
    print("[–¢–ï–°–¢ 2/4] –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞ 60 —Å–µ–∫—É–Ω–¥...")
    print("‚ö†Ô∏è  –°–ú–û–¢–†–ò–¢–ï –ù–ê nvidia-smi - GPU –î–û–õ–ñ–ù–ê –ë–´–¢–¨ 100%!")
    print()
    
    start = time.time()
    iteration = 0
    
    while time.time() - start < 60:
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç—è–∂—ë–ª—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
        x = torch.randn(10000, 10000, device=device)
        y = torch.randn(10000, 10000, device=device)
        
        # –£–º–Ω–æ–∂–µ–Ω–∏–µ
        z = torch.matmul(x, y)
        
        # –ë–æ–ª—å—à–µ –æ–ø–µ—Ä–∞—Ü–∏–π
        z = torch.sin(z)
        z = torch.cos(z)
        z = torch.exp(z * 0.01)  # –ß—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ overflow
        z = torch.sigmoid(z)
        
        # –ï—â—ë –æ–ø–µ—Ä–∞—Ü–∏–∏
        w = torch.matmul(z, z.t())
        w = torch.relu(w)
        w = torch.softmax(w, dim=1)
        
        iteration += 1
        
        if iteration % 5 == 0:
            elapsed = time.time() - start
            print(f"  {elapsed:.1f} —Å–µ–∫ | –ò—Ç–µ—Ä–∞—Ü–∏—è {iteration} | "
                  f"VRAM: {torch.cuda.memory_allocated(0) / 1024**2:.0f} MB | "
                  f"GPU: 100%?")
    
    print()
    print("‚úì –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à—ë–Ω!")
    print()
    
    # ========================================================================
    # –¢–ï–°–¢ 3: –ù–ï–ô–†–û–°–ï–¢–¨
    # ========================================================================
    print("[–¢–ï–°–¢ 3/4] –û–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏...")
    print()
    
    import torch.nn as nn
    import torch.optim as optim
    
    # –ë–æ–ª—å—à–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å
    model = nn.Sequential(
        nn.Linear(10000, 5000),
        nn.ReLU(),
        nn.Linear(5000, 2000),
        nn.ReLU(),
        nn.Linear(2000, 1000),
        nn.ReLU(),
        nn.Linear(1000, 100)
    ).to(device)
    
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()
    
    print("–û–±—É—á–µ–Ω–∏–µ –Ω–∞ 200 –±–∞—Ç—á–∞—Ö...")
    
    for i in range(200):
        # –î–∞–Ω–Ω—ã–µ
        x = torch.randn(512, 10000, device=device)
        y = torch.randn(512, 100, device=device)
        
        # Forward
        optimizer.zero_grad()
        output = model(x)
        loss = criterion(output, y)
        
        # Backward
        loss.backward()
        optimizer.step()
        
        if i % 20 == 0:
            print(f"  –ë–∞—Ç—á {i}/200 | Loss: {loss.item():.4f} | "
                  f"VRAM: {torch.cuda.memory_allocated(0) / 1024**2:.0f} MB")
    
    print()
    print("‚úì –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print()
    
    # ========================================================================
    # –¢–ï–°–¢ 4: SENTENCE-TRANSFORMERS
    # ========================================================================
    print("[–¢–ï–°–¢ 4/4] SentenceTransformer –Ω–∞ GPU...")
    print()
    
    try:
        from sentence_transformers import SentenceTransformer
        
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ GPU...")
        model = SentenceTransformer(
            'paraphrase-multilingual-MiniLM-L12-v2',
            device='cuda'
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–∞ GPU
        print(f"–ú–æ–¥–µ–ª—å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {model.device}")
        
        # –ë–æ–ª—å—à–æ–π –±–∞—Ç—á
        texts = [
            f"–¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –Ω–æ–º–µ—Ä {i} –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏ GPU"
            for i in range(10000)
        ]
        
        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤...")
        print()
        
        start = time.time()
        
        embeddings = model.encode(
            texts,
            batch_size=1024,  # –ë–æ–ª—å—à–æ–π –±–∞—Ç—á
            convert_to_tensor=True,
            device='cuda',
            show_progress_bar=True,
            normalize_embeddings=True
        )
        
        elapsed = time.time() - start
        
        print()
        print(f"‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞ {elapsed:.1f} —Å–µ–∫")
        print(f"‚úì –°–∫–æ—Ä–æ—Å—Ç—å: {len(texts)/elapsed:.0f} —Ç–µ–∫—Å—Ç–æ–≤/—Å–µ–∫")
        print(f"‚úì Embeddings –Ω–∞ GPU: {embeddings.is_cuda}")
        print()
        
    except ImportError:
        print("‚ö†Ô∏è  sentence-transformers –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        print("   pip install sentence-transformers")
        print()
    
    # ========================================================================
    # –ò–¢–û–ì–ò
    # ========================================================================
    print("="*80)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–û–í")
    print("="*80)
    print()
    
    print("–ß—Ç–æ –±—ã–ª–æ –∑–∞–ø—É—â–µ–Ω–æ:")
    print("  ‚úì –£–º–Ω–æ–∂–µ–Ω–∏–µ –æ–≥—Ä–æ–º–Ω—ã—Ö –º–∞—Ç—Ä–∏—Ü 15000x15000")
    print("  ‚úì –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ 60 —Å–µ–∫—É–Ω–¥")
    print("  ‚úì –û–±—É—á–µ–Ω–∏–µ –±–æ–ª—å—à–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")
    print("  ‚úì SentenceTransformer embeddings")
    print()
    
    print("–ß—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã–ª–æ –ø—Ä–æ–∏–∑–æ–π—Ç–∏ –≤ nvidia-smi:")
    print()
    print("  GPU-Util: 95-100%  ‚Üê –í–´ –≠–¢–û –í–ò–î–ï–õ–ò?")
    print("  Memory:   12000+ MB")
    print("  Temp:     70-80¬∞C")
    print()
    
    response = input("GPU –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å –¥–æ 90%+? (yes/no): ").strip().lower()
    print()
    
    if response in ['yes', 'y', '–¥–∞', '–¥']:
        print("‚úÖ –û–¢–õ–ò–ß–ù–û! GPU —Ä–∞–±–æ—Ç–∞–µ—Ç!")
        print()
        print("–¢–µ–ø–µ—Ä—å JARVIS –¥–æ–ª–∂–µ–Ω —Ä–∞–±–æ—Ç–∞—Ç—å —Å –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π GPU.")
        print()
        print("–ó–∞–ø—É—Å–∫–∞–π—Ç–µ:")
        print("  python -m jarvis")
        print()
    else:
        print("‚ùå GPU –ù–ï –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å!")
        print()
        print("–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:")
        print()
        print("1. ‚ùå –î—Ä–∞–π–≤–µ—Ä—ã —É—Å—Ç–∞—Ä–µ–ª–∏")
        print("   –°–∫–∞—á–∞–π—Ç–µ: https://www.nvidia.com/download/index.aspx")
        print("   –ù—É–∂–µ–Ω –¥—Ä–∞–π–≤–µ—Ä 525.60.11+ –¥–ª—è RTX 4070 Ti SUPER")
        print()
        print("2. ‚ùå PyTorch –≤—Å—ë –µ—â—ë —Å CUDA 11.7")
        print("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ: import torch; print(torch.version.cuda)")
        print("   –î–æ–ª–∂–Ω–æ –±—ã—Ç—å: 12.1")
        print()
        print("3. ‚ùå GPU –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞ –≤ BIOS")
        print("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ BIOS")
        print()
        print("4. ‚ùå TCC —Ä–µ–∂–∏–º (Data Center GPU)")
        print("   –í—ã–ø–æ–ª–Ω–∏—Ç–µ: nvidia-smi -dm 0")
        print()
        print("5. ‚ùå –ü—Ä–æ–±–ª–µ–º–∞ —Å PCI-E")
        print("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ –∫–∞—Ä—Ç–∞ –≤ —Å–ª–æ—Ç–µ x16")
        print("   nvidia-smi -q | findstr \"Link Width\"")
        print()

except Exception as e:
    print(f"‚ùå –û–®–ò–ë–ö–ê –¢–ï–°–¢–ê: {e}")
    import traceback
    traceback.print_exc()
    print()

print("="*80)

input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")
