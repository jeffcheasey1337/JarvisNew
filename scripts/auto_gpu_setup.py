# -*- coding: utf-8 -*-
"""
üéÆ JARVIS AUTO GPU SETUP & FIX
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ GPU

–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:
‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥—Ä–∞–π–≤–µ—Ä—ã NVIDIA
‚úÖ –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≤–µ—Ä—Å–∏—é CUDA
‚úÖ –£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–π PyTorch
‚úÖ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π PyTorch —Å CUDA
‚úÖ –¢–µ—Å—Ç–∏—Ä—É–µ—Ç GPU
‚úÖ –í—Å—ë –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!

–ü—Ä–æ—Å—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python auto_gpu_setup.py
"""

import subprocess
import sys
import os
import re
from pathlib import Path
import time

class Colors:
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'

def print_header(text):
    print(f"\n{Colors.CYAN}{Colors.BOLD}{'='*80}{Colors.ENDC}")
    print(f"{Colors.CYAN}{Colors.BOLD}{text.center(80)}{Colors.ENDC}")
    print(f"{Colors.CYAN}{Colors.BOLD}{'='*80}{Colors.ENDC}\n")

def print_success(text):
    print(f"  {Colors.GREEN}‚úì{Colors.ENDC} {text}")

def print_warning(text):
    print(f"  {Colors.YELLOW}‚ö†{Colors.ENDC} {text}")

def print_error(text):
    print(f"  {Colors.RED}‚úó{Colors.ENDC} {text}")

def print_info(text):
    print(f"  {Colors.BLUE}‚Ñπ{Colors.ENDC} {text}")

def print_step(step, total, text):
    print(f"\n{Colors.BOLD}[{step}/{total}]{Colors.ENDC} {text}")


class AutoGPUSetup:
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ GPU"""
    
    def __init__(self):
        self.total_steps = 8
        self.current_step = 0
        self.nvidia_available = False
        self.cuda_version = None
        self.pytorch_cuda = False
        self.gpu_name = None
    
    def step(self, text):
        self.current_step += 1
        print_step(self.current_step, self.total_steps, text)
    
    def check_nvidia_driver(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä–∞–π–≤–µ—Ä–∞ NVIDIA"""
        self.step("–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä–∞–π–≤–µ—Ä–∞ NVIDIA...")
        
        try:
            result = subprocess.run(
                ['nvidia-smi'],
                capture_output=True,
                text=True,
                timeout=10
            )
            
            if result.returncode == 0:
                output = result.stdout
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–µ—Ä—Å–∏—é –¥—Ä–∞–π–≤–µ—Ä–∞
                driver_match = re.search(r'Driver Version: ([\d.]+)', output)
                if driver_match:
                    driver_version = driver_match.group(1)
                    print_success(f"–î—Ä–∞–π–≤–µ—Ä NVIDIA: {driver_version}")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–µ—Ä—Å–∏—é CUDA
                cuda_match = re.search(r'CUDA Version: ([\d.]+)', output)
                if cuda_match:
                    self.cuda_version = cuda_match.group(1)
                    print_success(f"CUDA Version: {self.cuda_version}")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ GPU
                gpu_match = re.search(r'NVIDIA GeForce ([^\|]+)', output)
                if gpu_match:
                    self.gpu_name = gpu_match.group(1).strip()
                    print_success(f"GPU: NVIDIA GeForce {self.gpu_name}")
                
                self.nvidia_available = True
                return True
            else:
                print_error("nvidia-smi –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É")
                return False
        
        except FileNotFoundError:
            print_error("nvidia-smi –Ω–µ –Ω–∞–π–¥–µ–Ω - –¥—Ä–∞–π–≤–µ—Ä—ã NVIDIA –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
            self._show_driver_installation_guide()
            return False
        
        except subprocess.TimeoutExpired:
            print_error("Timeout –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ nvidia-smi")
            return False
        
        except Exception as e:
            print_error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ NVIDIA: {e}")
            return False
    
    def _show_driver_installation_guide(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ –¥—Ä–∞–π–≤–µ—Ä–æ–≤"""
        print()
        print_warning("–î—Ä–∞–π–≤–µ—Ä—ã NVIDIA –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã!")
        print()
        print("üì• –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –¥—Ä–∞–π–≤–µ—Ä—ã:")
        print()
        print("1. –û—Ç–∫—Ä–æ–π—Ç–µ: https://www.nvidia.com/Download/index.aspx")
        print("2. –í—ã–±–µ—Ä–∏—Ç–µ:")
        print("   - Product Type: GeForce")
        print("   - Product Series: GeForce RTX 40 Series")
        print("   - Product: GeForce RTX 4070 Ti SUPER")
        print("   - Operating System: Windows 11")
        print("3. –ù–∞–∂–º–∏—Ç–µ Search ‚Üí Download ‚Üí Install")
        print("4. –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ –∫–æ–º–ø—å—é—Ç–µ—Ä")
        print("5. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —ç—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç —Å–Ω–æ–≤–∞")
        print()
    
    def check_pytorch_cuda(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ PyTorch CUDA"""
        self.step("–ü—Ä–æ–≤–µ—Ä–∫–∞ PyTorch...")
        
        try:
            import torch
            
            print_info(f"PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
            
            cuda_available = torch.cuda.is_available()
            
            if cuda_available:
                print_success(f"PyTorch CUDA: –î–æ—Å—Ç—É–ø–Ω–∞")
                print_success(f"CUDA –≤–µ—Ä—Å–∏—è –≤ PyTorch: {torch.version.cuda}")
                
                device_count = torch.cuda.device_count()
                print_success(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ GPU: {device_count}")
                
                if device_count > 0:
                    gpu_name = torch.cuda.get_device_name(0)
                    print_success(f"GPU[0]: {gpu_name}")
                
                self.pytorch_cuda = True
                return True
            else:
                print_error("PyTorch CUDA: –ù–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
                print_warning("PyTorch —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –±–µ–∑ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ CUDA!")
                self.pytorch_cuda = False
                return False
        
        except ImportError:
            print_warning("PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return False
        
        except Exception as e:
            print_error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ PyTorch: {e}")
            return False
    
    def determine_cuda_toolkit_version(self):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ CUDA Toolkit –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏"""
        self.step("–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ CUDA...")
        
        if not self.cuda_version:
            print_warning("–í–µ—Ä—Å–∏—è CUDA –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º 12.1 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
            return "cu121"
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤–µ—Ä—Å–∏—é CUDA –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è PyTorch
        cuda_major = int(float(self.cuda_version))
        
        if cuda_major >= 12:
            print_success("–ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω PyTorch —Å CUDA 12.1")
            return "cu121"
        elif cuda_major >= 11:
            print_success("–ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω PyTorch —Å CUDA 11.8")
            return "cu118"
        else:
            print_warning(f"CUDA {self.cuda_version} —É—Å—Ç–∞—Ä–µ–ª–∞, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–±–Ω–æ–≤–∏—Ç—å –¥—Ä–∞–π–≤–µ—Ä—ã")
            return "cu118"
    
    def uninstall_old_pytorch(self):
        """–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ PyTorch"""
        self.step("–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ PyTorch...")
        
        packages = ['torch', 'torchvision', 'torchaudio']
        
        print_info("–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –ø–∞–∫–µ—Ç–æ–≤...")
        
        try:
            subprocess.run(
                [sys.executable, '-m', 'pip', 'uninstall', '-y'] + packages,
                capture_output=True,
                check=False
            )
            print_success("–°—Ç–∞—Ä—ã–µ –ø–∞–∫–µ—Ç—ã —É–¥–∞–ª–µ–Ω—ã")
            return True
        
        except Exception as e:
            print_error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è: {e}")
            return False
    
    def install_pytorch_with_cuda(self, cuda_version):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch —Å CUDA"""
        self.step(f"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch —Å CUDA ({cuda_version})...")
        
        print_info("–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 3-5 –º–∏–Ω—É—Ç...")
        print_info("–°–∫–∞—á–∏–≤–∞–µ—Ç—Å—è ~2-3 GB –¥–∞–Ω–Ω—ã—Ö...")
        print()
        
        index_url = f"https://download.pytorch.org/whl/{cuda_version}"
        
        packages = ['torch', 'torchvision', 'torchaudio']
        
        try:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            process = subprocess.Popen(
                [sys.executable, '-m', 'pip', 'install'] + packages + 
                ['--index-url', index_url],
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True
            )
            
            # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            for line in process.stdout:
                if 'Downloading' in line or 'Installing' in line:
                    print(f"  {Colors.BLUE}‚Üí{Colors.ENDC} {line.strip()}")
            
            process.wait()
            
            if process.returncode == 0:
                print()
                print_success("PyTorch —Å CUDA —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
                return True
            else:
                print()
                print_error("–û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ PyTorch")
                return False
        
        except Exception as e:
            print_error(f"–û—à–∏–±–∫–∞: {e}")
            return False
    
    def verify_gpu_setup(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ GPU"""
        self.step("–ü—Ä–æ–≤–µ—Ä–∫–∞ GPU...")
        
        try:
            import torch
            
            print()
            print_info("–ò–º–ø–æ—Ä—Ç PyTorch...")
            print_success("PyTorch –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
            
            cuda_available = torch.cuda.is_available()
            
            if cuda_available:
                print()
                print_success(f"‚úÖ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞!")
                print_success(f"‚úÖ PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
                print_success(f"‚úÖ CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")
                
                device_count = torch.cuda.device_count()
                print_success(f"‚úÖ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU: {device_count}")
                
                if device_count > 0:
                    gpu_name = torch.cuda.get_device_name(0)
                    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                    
                    print_success(f"‚úÖ GPU: {gpu_name}")
                    print_success(f"‚úÖ VRAM: {gpu_memory:.1f} GB")
                
                return True
            else:
                print_error("CUDA –≤—Å—ë –µ—â—ë –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏")
                return False
        
        except Exception as e:
            print_error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")
            return False
    
    def run_gpu_test(self):
        """–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ GPU"""
        self.step("–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ GPU...")
        
        try:
            import torch
            import time
            
            if not torch.cuda.is_available():
                print_warning("GPU –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è —Ç–µ—Å—Ç–∞")
                return False
            
            print()
            print_info("–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞...")
            
            # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç
            size = 5000
            iterations = 50
            
            # CPU —Ç–µ—Å—Ç
            print_info("–¢–µ—Å—Ç CPU...")
            cpu_start = time.time()
            for _ in range(iterations):
                a = torch.randn(size, size)
                b = torch.randn(size, size)
                c = torch.matmul(a, b)
            cpu_time = time.time() - cpu_start
            print_success(f"CPU –≤—Ä–µ–º—è: {cpu_time:.2f} —Å–µ–∫")
            
            # GPU —Ç–µ—Å—Ç
            print_info("–¢–µ—Å—Ç GPU...")
            gpu_start = time.time()
            for _ in range(iterations):
                a = torch.randn(size, size, device='cuda')
                b = torch.randn(size, size, device='cuda')
                c = torch.matmul(a, b)
            torch.cuda.synchronize()
            gpu_time = time.time() - gpu_start
            print_success(f"GPU –≤—Ä–µ–º—è: {gpu_time:.2f} —Å–µ–∫")
            
            # –£—Å–∫–æ—Ä–µ–Ω–∏–µ
            speedup = cpu_time / gpu_time
            print()
            print_success(f"üöÄ –£—Å–∫–æ—Ä–µ–Ω–∏–µ GPU: {speedup:.1f}x")
            
            if speedup > 5:
                print_success("‚úÖ GPU —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ!")
            elif speedup > 2:
                print_warning("‚ö†Ô∏è GPU —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ")
            else:
                print_error("‚ùå GPU —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
            
            return True
        
        except Exception as e:
            print_error(f"–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞: {e}")
            return False
    
    def show_final_summary(self):
        """–ò—Ç–æ–≥–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"""
        self.step("–ò—Ç–æ–≥–∏...")
        
        print_header("‚úÖ –ù–ê–°–¢–†–û–ô–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
        
        print(f"\n{Colors.BOLD}–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:{Colors.ENDC}\n")
        
        if self.nvidia_available:
            print_success(f"NVIDIA Driver: –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            if self.cuda_version:
                print_success(f"CUDA Version: {self.cuda_version}")
            if self.gpu_name:
                print_success(f"GPU: NVIDIA GeForce {self.gpu_name}")
        else:
            print_error("NVIDIA Driver: –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        print()
        
        if self.pytorch_cuda:
            print_success("PyTorch CUDA: –†–∞–±–æ—Ç–∞–µ—Ç ‚úÖ")
        else:
            print_error("PyTorch CUDA: –ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç ‚ùå")
        
        print()
        
        if self.nvidia_available and self.pytorch_cuda:
            print(f"{Colors.GREEN}{Colors.BOLD}üéâ GPU –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞!{Colors.ENDC}")
            print()
            print("–¢–µ–ø–µ—Ä—å JARVIS –±—É–¥–µ—Ç —É—á–∏—Ç—å—Å—è –≤ 50-100 —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ!")
            print()
            print(f"{Colors.BOLD}–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:{Colors.ENDC}")
            print()
            print("1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ—Å—Ç:")
            print(f"   {Colors.CYAN}python test_turbo_integration.py{Colors.ENDC}")
            print()
            print("2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ JARVIS:")
            print(f"   {Colors.CYAN}python -m jarvis{Colors.ENDC}")
            print()
            print("3. –û—Ç–∫—Ä–æ–π—Ç–µ Dashboard:")
            print(f"   {Colors.CYAN}python jarvis/gui/learning_dashboard.py{Colors.ENDC}")
        else:
            print(f"{Colors.RED}‚ùå –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞{Colors.ENDC}")
            print()
            
            if not self.nvidia_available:
                print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –¥—Ä–∞–π–≤–µ—Ä—ã NVIDIA –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç —Å–Ω–æ–≤–∞")
            elif not self.pytorch_cuda:
                print("PyTorch –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—Ä—É—á–Ω—É—é:")
                print(f"  {Colors.CYAN}pip install torch --index-url https://download.pytorch.org/whl/cu121{Colors.ENDC}")
    
    def run(self):
        """–ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"""
        print_header("üéÆ JARVIS AUTO GPU SETUP")
        
        print(f"{Colors.YELLOW}–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ GPU{Colors.ENDC}")
        print(f"{Colors.YELLOW}–í—Ä–µ–º—è: ~5-10 –º–∏–Ω—É—Ç{Colors.ENDC}\n")
        
        print(f"{Colors.BOLD}–ß—Ç–æ –±—É–¥–µ—Ç —Å–¥–µ–ª–∞–Ω–æ:{Colors.ENDC}")
        print("  ‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä–∞–π–≤–µ—Ä–æ–≤ NVIDIA")
        print("  ‚Ä¢ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ CUDA")
        print("  ‚Ä¢ –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ PyTorch")
        print("  ‚Ä¢ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch —Å CUDA")
        print("  ‚Ä¢ –¢–µ—Å—Ç GPU")
        print()
        
        response = input(f"{Colors.BOLD}–ù–∞—á–∞—Ç—å? (yes/no): {Colors.ENDC}").strip().lower()
        if response not in ['yes', 'y']:
            print_error("–û—Ç–º–µ–Ω–µ–Ω–æ")
            return False
        
        start_time = time.time()
        
        try:
            # –®–∞–≥ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä–∞–π–≤–µ—Ä–æ–≤
            nvidia_ok = self.check_nvidia_driver()
            
            if not nvidia_ok:
                print()
                print_error("–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –±–µ–∑ –¥—Ä–∞–π–≤–µ—Ä–æ–≤ NVIDIA")
                print_warning("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –¥—Ä–∞–π–≤–µ—Ä—ã –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç —Å–Ω–æ–≤–∞")
                return False
            
            # –®–∞–≥ 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ PyTorch
            pytorch_ok = self.check_pytorch_cuda()
            
            # –ï—Å–ª–∏ PyTorch —É–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å CUDA, –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
            if pytorch_ok and self.pytorch_cuda:
                print()
                print_success("PyTorch —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω —Å CUDA!")
                print_info("–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∫—É...")
                
                # –¢–æ–ª—å–∫–æ —Ç–µ—Å—Ç–∏—Ä—É–µ–º
                self.verify_gpu_setup()
                self.run_gpu_test()
                self.show_final_summary()
                return True
            
            # –®–∞–≥ 3: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ CUDA
            cuda_toolkit = self.determine_cuda_toolkit_version()
            
            # –®–∞–≥ 4: –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ PyTorch
            self.uninstall_old_pytorch()
            
            # –®–∞–≥ 5: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–æ–≤–æ–≥–æ PyTorch
            install_ok = self.install_pytorch_with_cuda(cuda_toolkit)
            
            if not install_ok:
                print_error("–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å PyTorch")
                return False
            
            # –®–∞–≥ 6: –ü—Ä–æ–≤–µ—Ä–∫–∞
            verify_ok = self.verify_gpu_setup()
            
            # –®–∞–≥ 7: –¢–µ—Å—Ç
            if verify_ok:
                self.run_gpu_test()
            
            # –®–∞–≥ 8: –ò—Ç–æ–≥–∏
            self.show_final_summary()
            
            elapsed = time.time() - start_time
            print()
            print(f"{Colors.GREEN}–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed/60:.1f} –º–∏–Ω—É—Ç{Colors.ENDC}")
            
            return verify_ok
        
        except Exception as e:
            print_error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
            return False


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    setup = AutoGPUSetup()
    success = setup.run()
    
    if success:
        print("\n" + "="*80)
        print("üéâ GPU –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")
        print("="*80)
    else:
        print("\n" + "="*80)
        print("‚ùå –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        print("="*80)
    
    input("\n\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")


if __name__ == "__main__":
    main()
