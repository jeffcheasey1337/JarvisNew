# -*- coding: utf-8 -*-
"""
ğŸ§ª JARVIS GPU TESTER - Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¸ Ñ‚ĞµÑÑ‚Ñ‹
Ğ‘ĞµĞ· ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸! Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ñ‡Ñ‚Ğ¾ Ğ²ÑÑ‘ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚.
"""

import subprocess
import sys
import re
import time

class Colors:
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'

def print_header(text):
    print(f"\n{Colors.CYAN}{Colors.BOLD}{'='*80}{Colors.ENDC}")
    print(f"{Colors.CYAN}{Colors.BOLD}{text.center(80)}{Colors.ENDC}")
    print(f"{Colors.CYAN}{Colors.BOLD}{'='*80}{Colors.ENDC}\n")

def print_success(text):
    print(f"  {Colors.GREEN}âœ“{Colors.ENDC} {text}")

def print_warning(text):
    print(f"  {Colors.YELLOW}âš {Colors.ENDC} {text}")

def print_error(text):
    print(f"  {Colors.RED}âœ—{Colors.ENDC} {text}")

def print_info(text):
    print(f"  {Colors.BLUE}â„¹{Colors.ENDC} {text}")


class GPUTester:
    """Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ GPU Ğ±ĞµĞ· ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸"""
    
    def __init__(self):
        self.nvidia_available = False
        self.cuda_version = None
        self.pytorch_cuda = False
        self.gpu_name = None
    
    def test_nvidia_driver(self):
        """Ğ¢ĞµÑÑ‚ 1: Ğ”Ñ€Ğ°Ğ¹Ğ²ĞµÑ€ NVIDIA"""
        print_header("Ğ¢Ğ•Ğ¡Ğ¢ 1: NVIDIA DRIVER")
        
        try:
            result = subprocess.run(
                ['nvidia-smi'],
                capture_output=True,
                text=True,
                timeout=10
            )
            
            if result.returncode == 0:
                output = result.stdout
                
                # Ğ’ĞµÑ€ÑĞ¸Ñ Ğ´Ñ€Ğ°Ğ¹Ğ²ĞµÑ€Ğ°
                driver_match = re.search(r'Driver Version: ([\d.]+)', output)
                if driver_match:
                    driver_version = driver_match.group(1)
                    print_success(f"Ğ”Ñ€Ğ°Ğ¹Ğ²ĞµÑ€ NVIDIA: {driver_version}")
                else:
                    print_warning("Ğ’ĞµÑ€ÑĞ¸Ñ Ğ´Ñ€Ğ°Ğ¹Ğ²ĞµÑ€Ğ° Ğ½Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ°")
                
                # CUDA Ğ²ĞµÑ€ÑĞ¸Ñ
                cuda_match = re.search(r'CUDA Version: ([\d.]+)', output)
                if cuda_match:
                    self.cuda_version = cuda_match.group(1)
                    print_success(f"CUDA Version: {self.cuda_version}")
                else:
                    print_warning("CUDA Ğ²ĞµÑ€ÑĞ¸Ñ Ğ½Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ°")
                
                # GPU Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ
                gpu_match = re.search(r'NVIDIA GeForce ([^\|]+)', output)
                if gpu_match:
                    self.gpu_name = gpu_match.group(1).strip()
                    print_success(f"GPU: NVIDIA GeForce {self.gpu_name}")
                else:
                    gpu_match2 = re.search(r'(NVIDIA [^\|]+)', output)
                    if gpu_match2:
                        self.gpu_name = gpu_match2.group(1).strip()
                        print_success(f"GPU: {self.gpu_name}")
                
                # Ğ¢ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ° Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
                temp_match = re.search(r'(\d+)C', output)
                if temp_match:
                    temp = temp_match.group(1)
                    print_info(f"Ğ¢ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ°: {temp}Â°C")
                
                util_match = re.search(r'(\d+)%', output)
                if util_match:
                    util = util_match.group(1)
                    print_info(f"Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ GPU: {util}%")
                
                self.nvidia_available = True
                print()
                print_success("âœ… NVIDIA Driver Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚!")
                return True
            else:
                print_error("nvidia-smi Ğ²ĞµÑ€Ğ½ÑƒĞ» Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ")
                return False
        
        except FileNotFoundError:
            print_error("nvidia-smi Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½")
            print()
            print_warning("Ğ”Ñ€Ğ°Ğ¹Ğ²ĞµÑ€Ñ‹ NVIDIA Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ñ‹!")
            print()
            print("Ğ¡ĞºĞ°Ñ‡Ğ°Ğ¹Ñ‚Ğµ Ğ¸ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ:")
            print("  https://www.nvidia.com/Download/index.aspx")
            return False
        
        except Exception as e:
            print_error(f"ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
            return False
    
    def test_pytorch(self):
        """Ğ¢ĞµÑÑ‚ 2: PyTorch"""
        print_header("Ğ¢Ğ•Ğ¡Ğ¢ 2: PYTORCH")
        
        try:
            import torch
            
            version = torch.__version__
            print_success(f"PyTorch ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½: {version}")
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° CUDA Ğ² PyTorch
            cuda_available = torch.cuda.is_available()
            
            if cuda_available:
                print_success("CUDA Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ° Ğ² PyTorch âœ…")
                
                cuda_version = torch.version.cuda
                print_success(f"CUDA Ğ²ĞµÑ€ÑĞ¸Ñ: {cuda_version}")
                
                device_count = torch.cuda.device_count()
                print_success(f"ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ GPU: {device_count}")
                
                if device_count > 0:
                    for i in range(device_count):
                        gpu_name = torch.cuda.get_device_name(i)
                        props = torch.cuda.get_device_properties(i)
                        vram = props.total_memory / (1024**3)
                        
                        print_success(f"GPU[{i}]: {gpu_name}")
                        print_info(f"  VRAM: {vram:.1f} GB")
                        print_info(f"  Compute Capability: {props.major}.{props.minor}")
                
                self.pytorch_cuda = True
                print()
                print_success("âœ… PyTorch CUDA Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚!")
                return True
            else:
                print_error("CUDA Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ° Ğ² PyTorch âŒ")
                print()
                print_warning("PyTorch ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ Ğ±ĞµĞ· Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¸ CUDA")
                print()
                print("ĞÑƒĞ¶Ğ½Ğ¾ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ²ĞµÑ€ÑĞ¸Ñ Ñ CUDA!")
                self.pytorch_cuda = False
                return False
        
        except ImportError:
            print_error("PyTorch Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ âŒ")
            print()
            print_warning("Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ PyTorch")
            return False
        
        except Exception as e:
            print_error(f"ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
            return False
    
    def test_gpu_performance(self):
        """Ğ¢ĞµÑÑ‚ 3: ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ GPU"""
        print_header("Ğ¢Ğ•Ğ¡Ğ¢ 3: ĞŸĞ ĞĞ˜Ğ—Ğ’ĞĞ”Ğ˜Ğ¢Ğ•Ğ›Ğ¬ĞĞĞ¡Ğ¢Ğ¬ GPU")
        
        try:
            import torch
            
            if not torch.cuda.is_available():
                print_warning("GPU Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ°, Ñ‚ĞµÑÑ‚ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½")
                return False
            
            print_info("Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ°...")
            print()
            
            size = 5000
            iterations = 50
            
            # CPU Ñ‚ĞµÑÑ‚
            print(f"  {Colors.BLUE}âš™ï¸  CPU Test...{Colors.ENDC}")
            cpu_times = []
            for _ in range(3):  # 3 Ğ¿Ñ€Ğ¾Ğ³Ğ¾Ğ½Ğ°
                start = time.time()
                for _ in range(iterations):
                    a = torch.randn(size, size)
                    b = torch.randn(size, size)
                    c = torch.matmul(a, b)
                cpu_times.append(time.time() - start)
            
            cpu_time = min(cpu_times)  # Ğ‘ĞµÑ€Ñ‘Ğ¼ Ğ»ÑƒÑ‡ÑˆĞ¸Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
            print_success(f"CPU Ğ²Ñ€ĞµĞ¼Ñ: {cpu_time:.2f} ÑĞµĞº")
            
            # GPU Ñ‚ĞµÑÑ‚
            print(f"\n  {Colors.GREEN}ğŸ®  GPU Test...{Colors.ENDC}")
            
            # Warm-up
            for _ in range(5):
                a = torch.randn(size, size, device='cuda')
                b = torch.randn(size, size, device='cuda')
                c = torch.matmul(a, b)
            torch.cuda.synchronize()
            
            gpu_times = []
            for _ in range(3):  # 3 Ğ¿Ñ€Ğ¾Ğ³Ğ¾Ğ½Ğ°
                start = time.time()
                for _ in range(iterations):
                    a = torch.randn(size, size, device='cuda')
                    b = torch.randn(size, size, device='cuda')
                    c = torch.matmul(a, b)
                torch.cuda.synchronize()
                gpu_times.append(time.time() - start)
            
            gpu_time = min(gpu_times)  # Ğ‘ĞµÑ€Ñ‘Ğ¼ Ğ»ÑƒÑ‡ÑˆĞ¸Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
            print_success(f"GPU Ğ²Ñ€ĞµĞ¼Ñ: {gpu_time:.2f} ÑĞµĞº")
            
            # Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
            speedup = cpu_time / gpu_time
            print()
            print(f"  {Colors.GREEN}{Colors.BOLD}ğŸš€ Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ GPU: {speedup:.1f}x{Colors.ENDC}")
            print()
            
            if speedup > 20:
                print_success("âœ… ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾! GPU Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğ° Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼!")
                print_info("JARVIS Ğ±ÑƒĞ´ĞµÑ‚ ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ² 50-100 Ñ€Ğ°Ğ· Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ!")
            elif speedup > 10:
                print_success("âœ… Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾! GPU Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾")
                print_info("JARVIS Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ ~50x")
            elif speedup > 5:
                print_warning("âš ï¸  ĞĞµĞ¿Ğ»Ğ¾Ñ…Ğ¾, Ğ½Ğ¾ GPU Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ")
                print_info("ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ´Ñ€Ğ°Ğ¹Ğ²ĞµÑ€Ñ‹ Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¿Ğ¸Ñ‚Ğ°Ğ½Ğ¸Ñ")
            elif speedup > 2:
                print_warning("âš ï¸  GPU Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ½ĞµĞµ Ğ¾Ğ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ğ¾Ğ³Ğ¾")
                print_info("Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ñ Ğ´Ñ€Ğ°Ğ¹Ğ²ĞµÑ€Ğ°Ğ¼Ğ¸ Ğ¸Ğ»Ğ¸ Ğ¿Ğ¸Ñ‚Ğ°Ğ½Ğ¸ĞµĞ¼")
            else:
                print_error("âŒ GPU Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ½Ğ¾!")
                print_info("ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºÑƒ Ğ´Ñ€Ğ°Ğ¹Ğ²ĞµÑ€Ğ¾Ğ² Ğ¸ PyTorch")
            
            return True
        
        except Exception as e:
            print_error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‚ĞµÑÑ‚Ğ°: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def show_summary(self):
        """Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ"""
        print_header("Ğ˜Ğ¢ĞĞ“Ğ˜ Ğ¢Ğ•Ğ¡Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ¯")
        
        print(f"{Colors.BOLD}Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹:{Colors.ENDC}\n")
        
        # NVIDIA
        if self.nvidia_available:
            print_success("NVIDIA Driver: âœ… Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚")
            if self.cuda_version:
                print_info(f"  CUDA: {self.cuda_version}")
            if self.gpu_name:
                print_info(f"  GPU: {self.gpu_name}")
        else:
            print_error("NVIDIA Driver: âŒ ĞĞµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚")
        
        print()
        
        # PyTorch
        if self.pytorch_cuda:
            print_success("PyTorch CUDA: âœ… Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚")
        else:
            print_error("PyTorch CUDA: âŒ ĞĞµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚")
        
        print()
        
        # Ğ’ĞµÑ€Ğ´Ğ¸ĞºÑ‚
        if self.nvidia_available and self.pytorch_cuda:
            print(f"{Colors.GREEN}{Colors.BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.ENDC}")
            print(f"{Colors.GREEN}{Colors.BOLD}  ğŸ‰ Ğ’Ğ¡Ğ Ğ“ĞĞ¢ĞĞ’Ğ!{Colors.ENDC}")
            print(f"{Colors.GREEN}{Colors.BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.ENDC}")
            print()
            print("GPU Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ° Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚!")
            print("JARVIS Ğ±ÑƒĞ´ĞµÑ‚ ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ² 50-100 Ñ€Ğ°Ğ· Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ!")
            print()
            print(f"{Colors.BOLD}ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°Ñ‚ÑŒ:{Colors.ENDC}")
            print(f"  {Colors.CYAN}python -m jarvis{Colors.ENDC}")
            print(f"  {Colors.CYAN}python jarvis/gui/learning_dashboard.py{Colors.ENDC}")
        else:
            print(f"{Colors.RED}{Colors.BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.ENDC}")
            print(f"{Colors.RED}{Colors.BOLD}  âŒ ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ ĞĞ• Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ{Colors.ENDC}")
            print(f"{Colors.RED}{Colors.BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.ENDC}")
            print()
            
            if not self.nvidia_available:
                print("âŒ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ Ğ´Ñ€Ğ°Ğ¹Ğ²ĞµÑ€Ñ‹ NVIDIA")
                print("   https://www.nvidia.com/Download/index.aspx")
                print()
            
            if not self.pytorch_cuda:
                print("âŒ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚Ğµ PyTorch Ñ CUDA")
                print("   Ğ¡Ğ¼. Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ñ Ğ½Ğ¸Ğ¶Ğµ â¬‡ï¸")
    
    def run(self):
        """Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ²ÑĞµÑ… Ñ‚ĞµÑÑ‚Ğ¾Ğ²"""
        print_header("ğŸ§ª JARVIS GPU TESTER")
        print()
        print("ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° GPU Ğ±ĞµĞ· ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸")
        print("Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚ĞµÑÑ‚Ñ‹!")
        print()
        
        input("ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter Ğ´Ğ»Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ°...")
        
        # Ğ¢ĞµÑÑ‚ 1: NVIDIA
        nvidia_ok = self.test_nvidia_driver()
        print()
        input("ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ...")
        
        # Ğ¢ĞµÑÑ‚ 2: PyTorch
        pytorch_ok = self.test_pytorch()
        print()
        
        if pytorch_ok:
            input("ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸...")
            
            # Ğ¢ĞµÑÑ‚ 3: ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ
            self.test_gpu_performance()
        
        print()
        input("ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter Ğ´Ğ»Ñ Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²...")
        
        # Ğ˜Ñ‚Ğ¾Ğ³Ğ¸
        self.show_summary()


def main():
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ"""
    tester = GPUTester()
    tester.run()
    
    input("\n\nĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter Ğ´Ğ»Ñ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ°...")


if __name__ == "__main__":
    main()
